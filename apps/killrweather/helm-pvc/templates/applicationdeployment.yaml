
apiVersion: v1
kind: Pod
metadata:
  name: killrweatherapp
spec:
  containers:
  - name: killrweatherapp
    image: {{ .Values.image.app}}:{{.Values.image.version }}
    command:
    - sh
    - -c
    - "/opt/spark/bin/spark-submit
        --master k8s://https://ibm.lightbend.com/
        --deploy-mode cluster
        --name killrweather
        --class {{ .Values.app.main }}
        --conf 'spark.executor.instances=3'
        --conf 'spark.driver.extraJavaOptions=-Dconfig.resource=cluster.conf'
        --conf 'spark.kubernetes.container.image={{ .Values.image.app}}:{{.Values.image.version }}'
        --conf 'spark.kubernetes.container.image.pullPolicy={{ .Values.image.pullPolicy}}'
        --conf 'spark.kubernetes.namespace=sample'
        --conf 'driver.memory=3g'
        --conf 'spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.options.claimName={{.Values.configuration.checkpointing.pvc}}'
        --conf 'spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.path={{.Values.configuration.streaming.checkpointDir}}'
        --conf 'spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false'
        --conf 'spark.kubernetes.driverEnv.KAFKA_BROKERS={{ .Values.configuration.kafka.brokerlist}}'
        --conf 'spark.kubernetes.driverEnv.CASSANDRA_HOSTS={{ .Values.configuration.cassandra.hosts}}'
        --conf 'spark.kubernetes.driverEnv.SPARK_BATCH_INTERVAL={{ .Values.configuration.streaming.batchInterval}}'
        --conf 'spark.kubernetes.driverEnv.GRAFANA_HOST={{ .Values.configuration.grafana.host}}'
        --conf 'spark.kubernetes.driverEnv.GRAFANA_PORT={{ .Values.configuration.grafana.port}}'
        --conf 'spark.kubernetes.driverEnv.INFLUXDB_HOST={{ .Values.configuration.influx.host}}'
        --conf 'spark.kubernetes.driverEnv.INFLUXDB_PORT={{ .Values.configuration.influx.port}}'
        --conf 'spark.kubernetes.driverEnv.CHECKPOINT_DIRECTORY=file://{{ .Values.configuration.streaming.checkpointDir}}'
        --conf 'spark.executor.extraJavaOptions=-Dconfig.resource=cluster.conf'
        --conf 'spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.options.claimName={{.Values.configuration.checkpointing.pvc}}'
        --conf 'spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.path={{.Values.configuration.streaming.checkpointDir}}'
        --conf 'spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false'
        --conf 'spark.executorEnv.KAFKA_BROKERS={{ .Values.configuration.kafka.brokerlist}}'
        --conf 'spark.executor.memory=3g'
        --conf 'spark.executorEnv.CASSANDRA_HOSTS={{ .Values.configuration.cassandra.hosts}}'
        --conf 'spark.executorEnv.SPARK_BATCH_INTERVAL={{ .Values.configuration.streaming.batchInterval}}'
        --conf 'spark.executorEnv.GRAFANA_HOST={{ .Values.configuration.grafana.host}}'
        --conf 'spark.executorEnv.GRAFANA_PORT={{ .Values.configuration.grafana.port}}'
        --conf 'spark.executorEnv.INFLUXDB_HOST={{ .Values.configuration.influx.host}}'
        --conf 'spark.executorEnv.INFLUXDB_PORT={{ .Values.configuration.influx.port}}'
        --conf 'spark.executorEnv.CHECKPOINT_DIRECTORY=file://{{ .Values.configuration.streaming.checkpointDir}}'
        local:///opt/spark/jars/{{ .Values.app.jar}}-{{.Values.image.version }}.jar"
  restartPolicy: Never